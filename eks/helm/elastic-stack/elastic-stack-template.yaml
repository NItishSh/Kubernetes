---
# Source: elastic-stack/charts/logstash/templates/poddisruptionbudget.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: elastic-stack-logstash
  labels:
    app: logstash
    chart: logstash-1.13.0
    release: elastic-stack
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: logstash
      release: elastic-stack
  maxUnavailable: 1
---
# Source: elastic-stack/charts/elasticsearch/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: elastic-stack-elasticsearch
  labels:
    app: elastic-stack-elasticsearch
    chart: "elasticsearch-1.29.0"
    release: "elastic-stack"
    heritage: "Helm"
data:
  elasticsearch.yml: |-
    cluster.name: elasticsearch

    node.data: ${NODE_DATA:true}
    node.master: ${NODE_MASTER:true}
    node.ingest: ${NODE_INGEST:true}
    node.name: ${HOSTNAME}

    network.host: 0.0.0.0
    # see https://github.com/kubernetes/kubernetes/issues/3595
    bootstrap.memory_lock: ${BOOTSTRAP_MEMORY_LOCK:false}

    discovery:
      zen:
        ping.unicast.hosts: ${DISCOVERY_SERVICE:}
        minimum_master_nodes: ${MINIMUM_MASTER_NODES:2}

    # see https://github.com/elastic/elasticsearch-definitive-guide/pull/679
    processors: ${PROCESSORS:}

    # avoid split-brain w/ a minimum consensus of two masters plus a data node
    gateway.expected_master_nodes: ${EXPECTED_MASTER_NODES:2}
    gateway.expected_data_nodes: ${EXPECTED_DATA_NODES:1}
    gateway.recover_after_time: ${RECOVER_AFTER_TIME:5m}
    gateway.recover_after_master_nodes: ${RECOVER_AFTER_MASTER_NODES:2}
    gateway.recover_after_data_nodes: ${RECOVER_AFTER_DATA_NODES:1}
  log4j2.properties: |-
    status = error
    appender.console.type = Console
    appender.console.name = console
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] %marker%m%n
    rootLogger.level = info
    rootLogger.appenderRef.console.ref = console
    logger.searchguard.name = com.floragunn
    logger.searchguard.level = info
    
  pre-stop-hook.sh: |-
    #!/bin/bash
    exec &> >(tee -a "/var/log/elasticsearch-hooks.log")
    NODE_NAME=${HOSTNAME}
    echo "Prepare to migrate data of the node ${NODE_NAME}"
    echo "Move all data from node ${NODE_NAME}"
    curl -s -XPUT -H 'Content-Type: application/json' 'elastic-stack-elasticsearch-client:9200/_cluster/settings' -d "{
      \"transient\" :{
          \"cluster.routing.allocation.exclude._name\" : \"${NODE_NAME}\"
      }
    }"
    echo ""

    while true ; do
      echo -e "Wait for node ${NODE_NAME} to become empty"
      SHARDS_ALLOCATION=$(curl -s -XGET 'http://elastic-stack-elasticsearch-client:9200/_cat/shards')
      if ! echo "${SHARDS_ALLOCATION}" | grep -E "${NODE_NAME}"; then
        break
      fi
      sleep 1
    done
    echo "Node ${NODE_NAME} is ready to shutdown"
  post-start-hook.sh: |-
    #!/bin/bash
    exec &> >(tee -a "/var/log/elasticsearch-hooks.log")
    NODE_NAME=${HOSTNAME}
    CLUSTER_SETTINGS=$(curl -s -XGET "http://elastic-stack-elasticsearch-client:9200/_cluster/settings")
    if echo "${CLUSTER_SETTINGS}" | grep -E "${NODE_NAME}"; then
      echo "Activate node ${NODE_NAME}"
      curl -s -XPUT -H 'Content-Type: application/json' "http://elastic-stack-elasticsearch-client:9200/_cluster/settings" -d "{
        \"transient\" :{
            \"cluster.routing.allocation.exclude._name\" : null
        }
      }"
    fi
    echo "Node ${NODE_NAME} is ready to be used"
---
# Source: elastic-stack/charts/elasticsearch/templates/tests/test-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: elastic-stack-elasticsearch-test
  labels:
    app: elastic-stack-elasticsearch
    chart: "elasticsearch-1.29.0"
    heritage: "Helm"
    release: "elastic-stack"
data:
  run.sh: |-
    @test "Test Access and Health" {
      curl -D - http://elastic-stack-elasticsearch-client:9200
      curl -D - http://elastic-stack-elasticsearch-client:9200/_cluster/health?wait_for_status=green
    }
---
# Source: elastic-stack/charts/kibana/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: elastic-stack-kibana
  labels:
    app: kibana
    chart: "kibana-3.2.1"
    release: elastic-stack
    heritage: Helm
data:
  kibana.yml: |
    elasticsearch.hosts: http://elasticsearch:9200
    server.host: "0"
    server.name: kibana
---
# Source: elastic-stack/charts/kibana/templates/tests/test-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: elastic-stack-kibana-test
  labels:
    app: elastic-stack-kibana
    chart: "kibana-3.2.1"
    heritage: "Helm"
    release: "elastic-stack"
data:
  run.sh: |-
    @test "Test Status" {
      url="http://elastic-stack-kibana:443/api/status"

      # retry for 1 minute
      run curl -s -o /dev/null -I -w "%{http_code}" --retry 30 --retry-delay 2 $url

      code=$(curl -s -o /dev/null -I -w "%{http_code}" $url)
      body=$(curl $url)
      if [ "$code" == "503" ]
      then
        skip "Kibana Unavailable (503), can't get status - see pod logs: $body"
      fi

      result=$(echo $body | jq -cr '.status.statuses[]')
      [ "$result" != "" ]

      result=$(echo $body | jq -cr '.status.statuses[] | select(.state != "green")')
      [ "$result" == "" ]
    }
---
# Source: elastic-stack/charts/logstash/templates/files-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: elastic-stack-logstash-files
  labels:
    app: logstash
    chart: logstash-1.13.0
    release: elastic-stack
    heritage: Helm
data:
binaryData:
---
# Source: elastic-stack/charts/logstash/templates/patterns-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: elastic-stack-logstash-patterns
  labels:
    app: logstash
    chart: logstash-1.13.0
    release: elastic-stack
    heritage: Helm
data:
---
# Source: elastic-stack/charts/logstash/templates/pipeline-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: elastic-stack-logstash-pipeline
  labels:
    app: logstash
    chart: logstash-1.13.0
    release: elastic-stack
    heritage: Helm
data:
  input_main: |-
    input {
      # udp {
      #   port => 1514
      #   type => syslog
      # }
      # tcp {
      #   port => 1514
      #   type => syslog
      # }
      beats {
        port => 5044
      }
      # http {
      #   port => 8080
      # }
      # kafka {
      #   ## ref: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html
      #   bootstrap_servers => "kafka-input:9092"
      #   codec => json { charset => "UTF-8" }
      #   consumer_threads => 1
      #   topics => ["source"]
      #   type => "example"
      # }
    }
  output_main: |-
    output {
      # stdout { codec => rubydebug }
      elasticsearch {
        hosts => ["${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}"]
        manage_template => false
        index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
        document_type => "%{[@metadata][type]}"
      }
      # kafka {
      #   ## ref: https://www.elastic.co/guide/en/logstash/current/plugins-outputs-kafka.html
      #   bootstrap_servers => "kafka-output:9092"
      #   codec => json { charset => "UTF-8" }
      #   compression_type => "lz4"
      #   topic_id => "destination"
      # }
    }
---
# Source: elastic-stack/charts/elasticsearch/templates/client-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: elasticsearch
    chart: elasticsearch-1.29.0
    component: "client"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-elasticsearch-client
---
# Source: elastic-stack/charts/elasticsearch/templates/data-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: elasticsearch
    chart: elasticsearch-1.29.0
    component: "data"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-elasticsearch-data
---
# Source: elastic-stack/charts/elasticsearch/templates/master-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: elasticsearch
    chart: elasticsearch-1.29.0
    component: "master"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-elasticsearch-master
---
# Source: elastic-stack/charts/elasticsearch/templates/client-svc.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: elasticsearch
    chart: elasticsearch-1.29.0
    component: "client"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-elasticsearch-client

spec:
  ports:
    - name: http
      port: 9200
      targetPort: http
  selector:
    app: elasticsearch
    component: "client"
    release: elastic-stack
  type: ClusterIP
---
# Source: elastic-stack/charts/elasticsearch/templates/master-svc.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: elasticsearch
    chart: elasticsearch-1.29.0
    component: "master"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-elasticsearch-discovery
spec:
  clusterIP: None
  ports:
    - port: 9300
      targetPort: transport
  selector:
    app: elasticsearch
    component: "master"
    release: elastic-stack
---
# Source: elastic-stack/charts/kibana/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: kibana
    chart: kibana-3.2.1
    release: elastic-stack
    heritage: Helm
  name: elastic-stack-kibana
spec:
  type: ClusterIP
  ports:
    - port: 443
      targetPort: 5601
      protocol: TCP

  selector:
    app: kibana
    release: elastic-stack
---
# Source: elastic-stack/charts/logstash/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: elastic-stack-logstash
  labels:
    app: logstash
    chart: logstash-1.13.0
    release: elastic-stack
    heritage: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: beats
      port: 5044
      protocol: TCP
      targetPort: beats
  selector:
    app: logstash
    release: elastic-stack
---
# Source: elastic-stack/charts/elasticsearch/templates/client-deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  labels:
    app: elasticsearch
    chart: elasticsearch-1.29.0
    component: "client"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-elasticsearch-client
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: elasticsearch
        component: "client"
        release: elastic-stack
      annotations:
        checksum/config: fb27c29b25c6ad1ccb7bf5424ab61d18d67a4ef1bd1d384cc3ff7a61a51b2a6e
    spec:
      serviceAccountName: elastic-stack-elasticsearch-client
      securityContext:
        fsGroup: 1000
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "elasticsearch"
                  release: "elastic-stack"
                  component: "client"
      initContainers:
      # see https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
      # and https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html#mlockall
      - name: "sysctl"
        image: "busybox:latest"
        imagePullPolicy: "Always"
        resources:
            {}
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
      containers:
      - name: elasticsearch
        env:
        - name: NODE_DATA
          value: "false"
        - name: NODE_MASTER
          value: "false"
        - name: DISCOVERY_SERVICE
          value: elastic-stack-elasticsearch-discovery
        - name: PROCESSORS
          valueFrom:
            resourceFieldRef:
              resource: limits.cpu
        - name: ES_JAVA_OPTS
          value: "-Djava.net.preferIPv4Stack=true -Xms512m -Xmx512m  "
        - name: MINIMUM_MASTER_NODES
          value: "2"
        resources:
            limits:
              cpu: "1"
            requests:
              cpu: 25m
              memory: 512Mi
        readinessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 5
        livenessProbe:
          httpGet:
            path: /_cluster/health?local=true
            port: 9200
          initialDelaySeconds: 90
        image: "docker.elastic.co/elasticsearch/elasticsearch-oss:6.7.0"
        imagePullPolicy: "IfNotPresent"
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          name: config
          subPath: elasticsearch.yml
      volumes:
      - name: config
        configMap:
          name: elastic-stack-elasticsearch
---
# Source: elastic-stack/charts/kibana/templates/deployment.yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  labels:
    app: kibana
    chart: "kibana-3.2.1"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-kibana
spec:
  replicas: 1
  revisionHistoryLimit: 3
  template:
    metadata:
      annotations:
        checksum/config: de4800f12b6f28ada60a41806c41a515dc1dc7ae702511cca76cd9fe928c9c83
      labels:
        app: kibana
        release: "elastic-stack"
    spec:
      serviceAccountName: default
      containers:
      - name: kibana
        image: "docker.elastic.co/kibana/kibana-oss:6.7.0"
        imagePullPolicy: IfNotPresent
        env:
        - name: "ELASTICSEARCH_HOSTS"
          value: "http://elastic-stack-elasticsearch-client:9200"
        ports:
        - containerPort: 5601
          name: kibana
          protocol: TCP
        resources:
          {}
        volumeMounts:
        - name: kibana
          mountPath: "/usr/share/kibana/config/kibana.yml"
          subPath: kibana.yml
      tolerations:
        []
      volumes:
        - name: kibana
          configMap:
            name: elastic-stack-kibana
---
# Source: elastic-stack/charts/elasticsearch/templates/data-statefulset.yaml
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  labels:
    app: elasticsearch
    chart: elasticsearch-1.29.0
    component: "data"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-elasticsearch-data
spec:
  serviceName: elastic-stack-elasticsearch-data
  replicas: 2
  template:
    metadata:
      labels:
        app: elasticsearch
        component: "data"
        release: elastic-stack
        role: data
    spec:
      serviceAccountName: elastic-stack-elasticsearch-data
      securityContext:
        fsGroup: 1000
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "elasticsearch"
                  release: "elastic-stack"
                  component: "data"
      initContainers:
      # see https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
      # and https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html#mlockall
      - name: "sysctl"
        image: "busybox:latest"
        imagePullPolicy: "Always"
        resources:
            {}
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
      - name: "chown"
        image: "docker.elastic.co/elasticsearch/elasticsearch-oss:6.7.0"
        imagePullPolicy: "IfNotPresent"
        resources:
            {}
        command:
        - /bin/bash
        - -c
        - >
          set -e;
          set -x;
          chown elasticsearch:elasticsearch /usr/share/elasticsearch/data;
          for datadir in $(find /usr/share/elasticsearch/data -mindepth 1 -maxdepth 1 -not -name ".snapshot"); do
            chown -R elasticsearch:elasticsearch $datadir;
          done;
          chown elasticsearch:elasticsearch /usr/share/elasticsearch/logs;
          for logfile in $(find /usr/share/elasticsearch/logs -mindepth 1 -maxdepth 1 -not -name ".snapshot"); do
            chown -R elasticsearch:elasticsearch $logfile;
          done
        securityContext:
          runAsUser: 0
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: data
      containers:
      - name: elasticsearch
        env:
        - name: DISCOVERY_SERVICE
          value: elastic-stack-elasticsearch-discovery
        - name: NODE_MASTER
          value: "false"
        - name: PROCESSORS
          valueFrom:
            resourceFieldRef:
              resource: limits.cpu
        - name: ES_JAVA_OPTS
          value: "-Djava.net.preferIPv4Stack=true -Xms1536m -Xmx1536m  "
        - name: MINIMUM_MASTER_NODES
          value: "2"
        image: "docker.elastic.co/elasticsearch/elasticsearch-oss:6.7.0"
        imagePullPolicy: "IfNotPresent"
        ports:
        - containerPort: 9300
          name: transport

        resources:
            limits:
              cpu: "1"
            requests:
              cpu: 25m
              memory: 1536Mi
        readinessProbe:
          httpGet:
            path: /_cluster/health?local=true
            port: 9200
          initialDelaySeconds: 5
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: data
        - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          name: config
          subPath: elasticsearch.yml
        - name: config
          mountPath: /pre-stop-hook.sh
          subPath: pre-stop-hook.sh
        - name: config
          mountPath: /post-start-hook.sh
          subPath: post-start-hook.sh
        lifecycle:
          preStop:
            exec:
              command: ["/bin/bash","/pre-stop-hook.sh"]
          postStart:
            exec:
              command: ["/bin/bash","/post-start-hook.sh"]
      terminationGracePeriodSeconds: 3600
      volumes:
      - name: config
        configMap:
          name: elastic-stack-elasticsearch
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
        - "ReadWriteOnce"
      resources:
        requests:
          storage: "30Gi"
---
# Source: elastic-stack/charts/elasticsearch/templates/master-statefulset.yaml
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  labels:
    app: elasticsearch
    chart: elasticsearch-1.29.0
    component: "master"
    heritage: Helm
    release: elastic-stack
  name: elastic-stack-elasticsearch-master
spec:
  serviceName: elastic-stack-elasticsearch-master
  replicas: 3
  template:
    metadata:
      labels:
        app: elasticsearch
        component: "master"
        release: elastic-stack
        role: master
    spec:
      serviceAccountName: elastic-stack-elasticsearch-master
      securityContext:
        fsGroup: 1000
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "elasticsearch"
                  release: "elastic-stack"
                  component: "master"
      initContainers:
      # see https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
      # and https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration-memory.html#mlockall
      - name: "sysctl"
        image: "busybox:latest"
        imagePullPolicy: "Always"
        resources:
            {}
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
      - name: "chown"
        image: "docker.elastic.co/elasticsearch/elasticsearch-oss:6.7.0"
        imagePullPolicy: "IfNotPresent"
        resources:
            {}
        command:
        - /bin/bash
        - -c
        - >
          set -e;
          set -x;
          chown elasticsearch:elasticsearch /usr/share/elasticsearch/data;
          for datadir in $(find /usr/share/elasticsearch/data -mindepth 1 -maxdepth 1 -not -name ".snapshot"); do
            chown -R elasticsearch:elasticsearch $datadir;
          done;
          chown elasticsearch:elasticsearch /usr/share/elasticsearch/logs;
          for logfile in $(find /usr/share/elasticsearch/logs -mindepth 1 -maxdepth 1 -not -name ".snapshot"); do
            chown -R elasticsearch:elasticsearch $logfile;
          done
        securityContext:
          runAsUser: 0
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: data
      containers:
      - name: elasticsearch
        env:
        - name: NODE_DATA
          value: "false"
        - name: DISCOVERY_SERVICE
          value: elastic-stack-elasticsearch-discovery
        - name: PROCESSORS
          valueFrom:
            resourceFieldRef:
              resource: limits.cpu
        - name: ES_JAVA_OPTS
          value: "-Djava.net.preferIPv4Stack=true -Xms512m -Xmx512m  "
        - name: MINIMUM_MASTER_NODES
          value: "2"
        resources:
            limits:
              cpu: "1"
            requests:
              cpu: 25m
              memory: 512Mi
        readinessProbe:
          httpGet:
            path: /_cluster/health?local=true
            port: 9200
          initialDelaySeconds: 5
        image: "docker.elastic.co/elasticsearch/elasticsearch-oss:6.7.0"
        imagePullPolicy: "IfNotPresent"
        ports:
        - containerPort: 9300
          name: transport

        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: data
        - mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          name: config
          subPath: elasticsearch.yml
      volumes:
      - name: config
        configMap:
          name: elastic-stack-elasticsearch
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: OnDelete
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes:
        - "ReadWriteOnce"
      resources:
        requests:
          storage: "4Gi"
---
# Source: elastic-stack/charts/logstash/templates/statefulset.yaml
apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  name: elastic-stack-logstash
  labels:
    app: logstash
    chart: logstash-1.13.0
    release: elastic-stack
    heritage: Helm
spec:
  serviceName: elastic-stack-logstash
  replicas: 1
  podManagementPolicy: OrderedReady
  selector:
    matchLabels:
      app: logstash
      release: elastic-stack
  template:
    metadata:
      labels:
        app: logstash
        release: elastic-stack
      annotations:
        checksum/patterns: b578abf3a738a03d3c36e45992239abe725e916e5391ddcdc836279e59610222
        checksum/templates: f00e4b1a8ee4bc68f03056fd6439c9ca2d42fe13510c5c53b509232ecb195741
        checksum/pipeline: 5d6098f385a16c2da6503c951b05e98ef49fe01b9e637b69e1dc1ce8f03afbeb
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      initContainers:
      containers:

        ## logstash
        - name: logstash
          image: "docker.elastic.co/logstash/logstash-oss:6.7.0"
          imagePullPolicy: IfNotPresent
          ports:
            - name: monitor
              containerPort: 9600
              protocol: TCP
            - containerPort: 5044
              name: beats
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: monitor
            initialDelaySeconds: 20
          readinessProbe:
            httpGet:
              path: /
              port: monitor
            initialDelaySeconds: 20
          env:
            ## Logstash monitoring API host and port env vars
            - name: HTTP_HOST
              value: "0.0.0.0"
            - name: HTTP_PORT
              value: "9600"
            ## Elasticsearch output
            - name: ELASTICSEARCH_HOST
              value: "elasticsearch-client.default.svc.cluster.local"
            - name: ELASTICSEARCH_PORT
              value: "9200"
            # Logstash Java Options
            - name: LS_JAVA_OPTS
              value: -Xmx1g -Xms1g
            ## Additional env vars
            - name: CONFIG_RELOAD_AUTOMATIC
              value: "true"
            - name: PATH_CONFIG
              value: "/usr/share/logstash/pipeline"
            - name: PATH_DATA
              value: "/usr/share/logstash/data"
            - name: QUEUE_CHECKPOINT_WRITES
              value: "1"
            - name: QUEUE_DRAIN
              value: "true"
            - name: QUEUE_MAX_BYTES
              value: "1gb"
            - name: QUEUE_TYPE
              value: "persisted"
          resources:
            {}
          volumeMounts:
            - mountPath: /usr/share/logstash/data
              name: data
            - mountPath: /usr/share/logstash/patterns
              name: patterns
            - mountPath: /usr/share/logstash/files
              name: files
            - mountPath: /usr/share/logstash/pipeline
              name: pipeline
      terminationGracePeriodSeconds: 30
      volumes:
        - name: patterns
          configMap:
            name: elastic-stack-logstash-patterns
        - name: files
          configMap:
            name: elastic-stack-logstash-files
        - name: pipeline
          configMap:
            name: elastic-stack-logstash-pipeline
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "2Gi"
---
# Source: elastic-stack/charts/elasticsearch/templates/tests/test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: elastic-stack-elasticsearch-test
  labels:
    app: elastic-stack-elasticsearch
    chart: "elasticsearch-1.29.0"
    heritage: "Helm"
    release: "elastic-stack"
  annotations:
    "helm.sh/hook": test-success
spec:
  initContainers:
    - name: test-framework
      image: "dduportal/bats:0.4.0"
      command:
      - "bash"
      - "-c"
      - |
        set -ex
        # copy bats to tools dir
        cp -R /usr/local/libexec/ /tools/bats/
      volumeMounts:
      - mountPath: /tools
        name: tools
  containers:
    - name: elastic-stack-test
      image: "dduportal/bats:0.4.0"
      command: ["/tools/bats/bats", "-t", "/tests/run.sh"]
      volumeMounts:
      - mountPath: /tests
        name: tests
        readOnly: true
      - mountPath: /tools
        name: tools
  volumes:
  - name: tests
    configMap:
      name: elastic-stack-elasticsearch-test
  - name: tools
    emptyDir: {}
  restartPolicy: Never
---
# Source: elastic-stack/charts/kibana/templates/tests/test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: elastic-stack-kibana-test
  labels:
    app: elastic-stack-kibana
    chart: "kibana-3.2.1"
    heritage: "Helm"
    release: "elastic-stack"
  annotations:
    "helm.sh/hook": test-success
spec:
  initContainers:
    - name: test-framework
      image: "dduportal/bats:0.4.0"
      command:
      - "bash"
      - "-c"
      - |
        set -ex
        # copy bats to tools dir
        cp -R /usr/local/libexec/ /tools/bats/
      volumeMounts:
      - mountPath: /tools
        name: tools
  containers:
    - name: elastic-stack-test
      image: "dwdraju/alpine-curl-jq"
      command: ["/tools/bats/bats", "-t", "/tests/run.sh"]
      volumeMounts:
        - mountPath: /tests
          name: tests
          readOnly: true
        - mountPath: /tools
          name: tools
  volumes:
  - name: tests
    configMap:
      name: elastic-stack-kibana-test
  - name: tools
    emptyDir: {}
  restartPolicy: Never
